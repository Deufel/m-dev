import re
import ast
import tomllib
import copy
import os
import tempfile
import shutil
import inspect
import sys
import importlib
import io
import zipfile
from tokenize import tokenize, COMMENT
from pathlib import Path
from textwrap import dedent, indent
from typing import Callable, Literal, Dict, Any, Tuple, TypedDict, List, Optional
from textwrap import dedent
from mistletoe import markdown
import numpy as np
from fastcore.docments import docments, docstring, empty

class ModuleInfo(TypedDict):
    name: str           # module name (without .py)
    imports: List[str]  # import statements (assuming strings; adjust if needed)
    exports: List[str]  # formatted source code (assuming strings)
    export_names: List[str]

class ScanResult(TypedDict):
    metadata: Optional[dict]  # or a more specific type if known
    readme_source: Optional[str]  # notebook path or None
    modules: List[ModuleInfo]

def is_marimo_export_decorator(
    decorator # the decorator that marimo attached to the cell
) -> bool:    # True if the function or cell is reusable - should match marimos detection
    "Check if decorator is app.function or app.class_definition (with or without args)"
    # If it's a call like @app.function(hide_code=True), check the func part
    if isinstance(decorator, ast.Call):
        decorator_name = ast.unparse(decorator.func)
    else:
        # Simple decorator like @app.function
        decorator_name = ast.unparse(decorator)

    return decorator_name in ['app.function', 'app.class_definition']

def validate_setup_metadata(
    setup_metadata: dict  # Package metadata from setup cell
) -> None:                # Raises ValueError if invalid
    """Validate that required metadata keys exist and have valid values for package generation"""

    required = ['__version__', '__description__', '__author__', '__license__']
    missing = [k for k in required if k not in setup_metadata]

    if missing:
        raise ValueError(
            f"Setup cell missing required metadata: {', '.join(missing)}\n\n"
            f"Add these to your setup cell:\n" + 
            '\n'.join([f"    {k} = '...'" for k in missing])
        )

    # Validate version
    version = setup_metadata['__version__']
    if not version or not version.strip():
        raise ValueError("__version__ cannot be empty")

    # Validate description
    desc = setup_metadata['__description__']
    if not desc or not desc.strip():
        raise ValueError("__description__ cannot be empty")

    # Validate author format
    author = setup_metadata['__author__']
    if not author or not author.strip():
        raise ValueError("__author__ cannot be empty")
    if '<' not in author or '>' not in author:
        raise ValueError("__author__ must be in format 'Name <email@example.com>'")

    email_part = author.split('<')[1].split('>')[0].strip()
    if not email_part or '@' not in email_part:
        raise ValueError(f"__author__ email '{email_part}' is not valid")

    # Validate license
    license_val = setup_metadata['__license__']
    if not license_val or not license_val.strip():
        raise ValueError("__license__ cannot be empty")

def scan_notebooks(
    notebooks_dir: str = 'notebooks', # Directory containing notebook files
    docstring_style: str = 'nbdev'    # Docstring style for all exports
) -> ScanResult:                      # A typed dict with the described structure.
    "Scan notebooks directory and extract all exports, metadata, and README"

    notebooks_path = Path(notebooks_dir)

    if not notebooks_path.exists():
        raise ValueError(f"Notebooks directory '{notebooks_dir}' does not exist")

    # Get all .py files, sorted
    notebook_files = sorted(notebooks_path.glob('*.py'))

    if not notebook_files:
        raise ValueError(f"No .py files found in '{notebooks_dir}'")

    metadata = None
    metadata_found_in = None
    readme_found_in = None
    modules = []

    for notebook_file in notebook_files:
        # Skip __pycache__ and hidden files
        if notebook_file.name.startswith('.') or notebook_file.name == '__pycache__':
            continue

        # Extract from this notebook
        nb_metadata, setup_imports, exports, export_names = extract_exports(
            str(notebook_file), 
            docstring_style
        )

        # Check for metadata (should only be in one file)
        if nb_metadata:
            if metadata_found_in:
                raise ValueError(
                    f"Project metadata defined in multiple notebooks:\n"
                    f"  - {metadata_found_in}\n"
                    f"  - {notebook_file.name}\n"
                    f"Metadata should only be defined in one notebook (typically 00_config.py)"
                )
            metadata = nb_metadata
            metadata_found_in = notebook_file.name

        # Check for README
        if has_readme_cell(str(notebook_file)):
            if readme_found_in:
                raise ValueError(
                    f"README defined in multiple notebooks:\n"
                    f"  - {readme_found_in}\n"
                    f"  - {notebook_file.name}\n"
                    f"README should only be defined in one notebook"
                )
            readme_found_in = str(notebook_file)

        # Store module info (even if no exports, we track the imports)
        module_name = notebook_file.stem  # filename without .py
        modules.append({
            'name': module_name,
            'imports': setup_imports,
            'exports': exports,
            'export_names': export_names
        })

    # Validate we found required metadata
    if not metadata:
        raise ValueError(
            f"No project metadata found in any notebook.\n"
            f"Add metadata to your config notebook (e.g., 00_config.py) in the setup cell:\n"
            f"    __version__ = '0.1.0'\n"
            f"    __description__ = 'My package'\n"
            f"    __author__ = 'Name <email@example.com>'\n"
            f"    __license__ = 'MIT'"
        )

    return {
        'metadata': metadata,
        'readme_source': readme_found_in,
        'modules': modules
    }

def has_readme_cell(
    notebook_path: str    # Dir with notebook files
) -> bool:                # truthy iff readme
    """Check if notebook contains a #| README cell at start of mo.md() content"""
    source_code = Path(notebook_path).read_text()

    # Extract mo.md() content
    content = extract_mo_md_content(source_code)
    if not content:
        return False

    # Check if #| README is on first non-empty line
    lines = content.strip().split('\n')
    if lines and lines[0].strip() == '#| README':
        return True

    return False

def extract_exports(
    notebook_path: str,             # Path to marimo notebook file
    docstring_style: str = 'nbdev'  # Target docstring format: 'google', 'numpy', or 'nbdev'
) -> tuple:                         # (setup_metadata, setup_imports, exports, export_names)
    "Extract metadata, imports, and exportable functions/classes from marimo notebook"

    source_code = Path(notebook_path).read_text()
    tree = ast.parse(source_code)

    setup_metadata = {}
    setup_imports = []
    exports = []
    export_names = []

    for node in tree.body:
        # Extract setup cell content
        if isinstance(node, ast.With):
            for stmt in node.body:
                if isinstance(stmt, ast.Assign):
                    setup_metadata[stmt.targets[0].id] = ast.literal_eval(stmt.value)
                elif isinstance(stmt, (ast.Import, ast.ImportFrom)):
                    setup_imports.append(ast.unparse(stmt))

        # Extract exportable functions/classes
        elif isinstance(node, (ast.FunctionDef, ast.ClassDef)):
            if any(is_marimo_export_decorator(d) for d in node.decorator_list):
                if node.name.startswith('test_'):
                    continue

                # Get original source
                original_source = ast.get_source_segment(source_code, node)

                # Remove marimo decorators
                lines = original_source.split('\n')
                filtered_lines = []
                for line in lines:
                    stripped = line.strip()
                    if not (stripped.startswith('@app.function') or 
                           stripped.startswith('@app.class_definition')):
                        filtered_lines.append(line)

                clean_source = '\n'.join(filtered_lines)

                # Reformat if needed
                if docstring_style != 'nbdev':
                    try:
                        docs = extract_param_docs_from_ast(clean_source)
                        formatted_source = build_formatted_docstring(
                            clean_source, docs, docstring_style
                        )
                        exports.append(formatted_source)
                    except Exception as e:
                        print(f"âš ï¸  Could not reformat {node.name}: {e}")
                        exports.append(clean_source)
                else:
                    exports.append(clean_source)

                export_names.append(node.name)

    return (setup_metadata, setup_imports, exports, export_names)

def extract_param_docs_from_ast(
    func_source: str  # Function source code as string
) -> dict:            # Dict mapping param names to {'anno': type, 'docment': comment}
    "Extract parameter docs using AST + tokenizer, no exec needed"

    # Parse AST to get parameter info
    tree = ast.parse(func_source)
    func_node = tree.body[0]

    # Get parameter line numbers and names from AST
    param_locs = {}
    for arg in func_node.args.args:
        param_locs[arg.lineno] = {
            'name': arg.arg,
            'anno': ast.unparse(arg.annotation) if arg.annotation else None
        }

    # Add *args if present
    if func_node.args.vararg:
        param_locs[func_node.args.vararg.lineno] = {
            'name': func_node.args.vararg.arg,
            'anno': None
        }

    # Add keyword-only args
    for arg in func_node.args.kwonlyargs:
        param_locs[arg.lineno] = {
            'name': arg.arg,
            'anno': ast.unparse(arg.annotation) if arg.annotation else None
        }

    # Add **kwargs if present
    if func_node.args.kwarg:
        param_locs[func_node.args.kwarg.lineno] = {
            'name': func_node.args.kwarg.arg,
            'anno': None
        }

    # Add return annotation
    if func_node.returns:
        param_locs[func_node.returns.lineno] = {
            'name': 'return',
            'anno': ast.unparse(func_node.returns)
        }

    # Tokenize to get comments
    tokens = tokenize(io.BytesIO(func_source.encode('utf-8')).readline)
    clean_re = re.compile(r'^\s*#(.*)\s*$')
    comments = {}
    for token in tokens:
        if token.type == COMMENT:
            match = clean_re.findall(token.string)
            if match:
                comments[token.start[0]] = match[0].strip()

    # Match comments to parameters
    result = {}
    for line, param_info in param_locs.items():
        name = param_info['name']
        comment = comments.get(line, '')
        result[name] = {
            'anno': param_info['anno'],
            'docment': comment
        }

    return result

def build_formatted_docstring(
    func_source: str,       # Original function source code
    docs: dict,             # Parameter docs from extract_param_docs_from_ast
    target_style: str       # 'google' or 'numpy'
) -> str:                   # Function source with reformatted docstring
    "Build formatted docstring from docs dict"

    tree = ast.parse(func_source)
    func_node = tree.body[0]
    existing_doc = ast.get_docstring(func_node) or ""

    lines = [existing_doc.strip()] if existing_doc else []

    if target_style == 'google':
        params = {k: v for k, v in docs.items() if k != 'return' and v.get('docment')}
        if params:
            lines.append("")
            lines.append("Args:")
            for name, info in params.items():
                anno = info.get('anno', '')
                doc = info.get('docment', '')
                if anno:
                    lines.append(f"    {name} ({anno}): {doc}")
                else:
                    lines.append(f"    {name}: {doc}")

        ret = docs.get('return')
        if ret and ret.get('docment'):
            lines.append("")
            lines.append("Returns:")
            ret_anno = ret.get('anno', '')
            ret_doc = ret.get('docment', '')
            if ret_anno:
                lines.append(f"    {ret_anno}: {ret_doc}")
            else:
                lines.append(f"    {ret_doc}")

    elif target_style == 'numpy':
        params = {k: v for k, v in docs.items() if k != 'return' and v.get('docment')}
        if params:
            lines.append("")
            lines.append("Parameters")
            lines.append("----------")
            for name, info in params.items():
                anno = info.get('anno', '')
                doc = info.get('docment', '')
                if anno:
                    lines.append(f"{name} : {anno}")
                else:
                    lines.append(f"{name}")
                if doc:
                    lines.append(f"    {doc}")

        ret = docs.get('return')
        if ret and ret.get('docment'):
            lines.append("")
            lines.append("Returns")
            lines.append("-------")
            ret_anno = ret.get('anno', '')
            ret_doc = ret.get('docment', '')
            if ret_anno:
                lines.append(f"{ret_anno}")
            if ret_doc:
                lines.append(f"    {ret_doc}")

    new_docstring = '\n'.join(lines)

    # Replace docstring in AST
    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
            if (node.body and isinstance(node.body[0], ast.Expr) 
                and isinstance(node.body[0].value, ast.Constant)):
                node.body[0].value.value = new_docstring
            else:
                doc_node = ast.Expr(value=ast.Constant(value=new_docstring))
                node.body.insert(0, doc_node)
            break

    return ast.unparse(tree)

def update_pyproject_toml(
    setup_metadata: dict,      # Package metadata from setup cell
    pyproject_path: str = "pyproject.toml"  # Path to pyproject.toml
) -> str:                      # Path to updated file
    "Update pyproject.toml with metadata from notebook setup cell"

    # Validate metadata first
    validate_setup_metadata(setup_metadata)

    # Read existing pyproject.toml
    with open(pyproject_path, 'rb') as f:
        config = tomllib.load(f)

    # Update [project] section with required fields
    if 'project' not in config:
        config['project'] = {}

    config['project']['version'] = setup_metadata['__version__']
    config['project']['description'] = setup_metadata['__description__']
    config['project']['license'] = {'text': setup_metadata['__license__']}

    # Parse author
    author_name = setup_metadata['__author__'].split('<')[0].strip()
    author_email = setup_metadata['__author__'].split('<')[1].strip('>')
    config['project']['authors'] = [{'name': author_name, 'email': author_email}]

    # Add optional fields if present
    if '__keywords__' in setup_metadata and setup_metadata['__keywords__']:
        config['project']['keywords'] = setup_metadata['__keywords__']

    if '__classifiers__' in setup_metadata and setup_metadata['__classifiers__']:
        config['project']['classifiers'] = setup_metadata['__classifiers__']

    # Add project URLs if present
    if any(k in setup_metadata for k in ['__repository__', '__homepage__', '__documentation__']):
        config['project']['urls'] = {}
        if '__repository__' in setup_metadata:
            config['project']['urls']['Repository'] = setup_metadata['__repository__']
        if '__homepage__' in setup_metadata:
            config['project']['urls']['Homepage'] = setup_metadata['__homepage__']
        if '__documentation__' in setup_metadata:
            config['project']['urls']['Documentation'] = setup_metadata['__documentation__']

    # Write back using tomlkit to preserve formatting
    try:
        import tomlkit
        with open(pyproject_path, 'r') as f:
            doc = tomlkit.load(f)

        # Update with new values
        if 'project' not in doc:
            doc['project'] = {}

        doc['project']['version'] = setup_metadata['__version__']
        doc['project']['description'] = setup_metadata['__description__']
        doc['project']['license'] = {'text': setup_metadata['__license__']}
        doc['project']['authors'] = [{'name': author_name, 'email': author_email}]

        if '__keywords__' in setup_metadata and setup_metadata['__keywords__']:
            doc['project']['keywords'] = setup_metadata['__keywords__']

        if '__classifiers__' in setup_metadata and setup_metadata['__classifiers__']:
            doc['project']['classifiers'] = setup_metadata['__classifiers__']

        if any(k in setup_metadata for k in ['__repository__', '__homepage__', '__documentation__']):
            if 'urls' not in doc['project']:
                doc['project']['urls'] = {}
            if '__repository__' in setup_metadata:
                doc['project']['urls']['Repository'] = setup_metadata['__repository__']
            if '__homepage__' in setup_metadata:
                doc['project']['urls']['Homepage'] = setup_metadata['__homepage__']
            if '__documentation__' in setup_metadata:
                doc['project']['urls']['Documentation'] = setup_metadata['__documentation__']

        with open(pyproject_path, 'w') as f:
            tomlkit.dump(doc, f)

    except ImportError:
        # Fallback if tomlkit not available - just append to file
        print("âš ï¸  tomlkit not available, using basic TOML writing")
        import json
        # This is a simple fallback - you might want to use tomli-w instead
        with open(pyproject_path, 'a') as f:
            f.write(f"\n# Updated by m-dev\n")

    print(f"âœ… Updated {pyproject_path} with metadata")
    return pyproject_path

def write_module(
    module_name: str,        # Name of the module (without .py)
    setup_imports: list,     # Import statements from setup cell
    exports: list,           # Exported function/class source code
    output_file: str         # Path for output file
) -> str:                    # Path to written file
    "Write Python module file with imports and exported code"
    with Path(output_file).open('w') as f:
        # Write imports
        if setup_imports:
            for imp in setup_imports:
                f.write(imp + '\n')
            f.write('\n')

        # Write exports
        for export in exports:
            f.write(export + '\n\n')

    return output_file

def write_init(
    package_name: str,       # Package name
    metadata: dict,          # Project metadata from setup cell
    modules: list,           # List of module dicts from scan_notebooks
    output_file: str         # Path to __init__.py
) -> str:                    # Path to written file
    "Write package __init__.py with metadata and cross-module imports "

    with Path(output_file).open('w') as f:
        # Write package docstring
        description = metadata.get('__description__', 'No description provided')
        f.write(f'"""{description}"""\n\n')

        # Write metadata
        f.write(f"__version__ = '{metadata['__version__']}'\n")

        if '__author__' in metadata:
            author_name = metadata['__author__'].split('<')[0].strip()
            f.write(f"__author__ = '{author_name}'\n")

        f.write('\n')

        # Collect all export names across modules
        all_exports = []

        # Write imports from submodules
        for module in modules:
            # Skip the config module (00_config or similar) - no exports usually
            if module['name'].startswith('00_') or not module['export_names']:
                continue

            if module['export_names']:
                exports_str = ', '.join(module['export_names'])
                f.write(f"from .{module['name']} import {exports_str}\n")
                all_exports.extend(module['export_names'])

        # Write __all__
        if all_exports:
            f.write('\n')
            f.write('__all__ = [\n')
            for name in all_exports:
                f.write(f'    "{name}",\n')
            f.write(']\n')

    print(f"âœ… Generated {output_file}")
    return output_file

def extract_readme(
    notebook_path: str,      # Path to the marimo notebook file
    output_dir: str,         # Directory where README.md will be written
    setup_metadata: dict     # Setup cell metadata for f-string substitution
) -> str:                    # Path to written README.md file, or empty string if no readme cell found
    "Extract README from notebook cell marked with #| readme and write to output directory"

    source_code = Path(notebook_path).read_text()

    tree = ast.parse(source_code)
    readme_contents = []

    # Check both regular cells (FunctionDef) and setup cells (With blocks)
    for node in tree.body:
        # Check @app.cell decorated functions (hidden or not)
        if isinstance(node, ast.FunctionDef):
            func_source = ast.get_source_segment(source_code, node)
            if func_source and 'mo.md(' in func_source and '#| README' in func_source:
                # Extract the string content from mo.md(...)
                content = extract_mo_md_content(func_source)
                if content and '#| README' in content:
                    lines = content.split('\n')
                    readme_text = '\n'.join(line for line in lines if not line.strip().startswith('#| README'))
                    readme_contents.append(readme_text.strip())

        # Check setup cell (with app.setup:)
        elif isinstance(node, ast.With):
            for stmt in node.body:
                if isinstance(stmt, ast.Expr):
                    stmt_source = ast.get_source_segment(source_code, stmt)
                    if stmt_source and 'mo.md(' in stmt_source and '#| README' in stmt_source:
                        content = extract_mo_md_content(stmt_source)
                        if content and '#| README' in content:
                            lines = content.split('\n')
                            readme_text = '\n'.join(line for line in lines if not line.strip().startswith('#| README'))
                            readme_contents.append(readme_text.strip())

    if len(readme_contents) == 0:
        print('âš ï¸  Warning: No #| README cell found. README.md will not be generated.')
        print('   For PyPI distribution, consider adding a cell with mo.md() containing #| README')
        return ''

    if len(readme_contents) > 1:
        print(f'âš ï¸  Warning: Found {len(readme_contents)} cells with #| README marker. Using only the first one.')

    # Substitute f-string variables from setup_metadata
    readme_text = readme_contents[0]
    for key, value in setup_metadata.items():
        readme_text = readme_text.replace(f'{{{key}}}', str(value))

    readme_path = Path(output_dir) / 'README.md'
    readme_path.write_text(readme_text)

    print(f'âœ… README.md generated from notebook')
    return str(readme_path)

def extract_mo_md_content(source: str) -> str:
    "Extract the string content from a mo.md() call, handling r/f/rf string prefixes"
    # Find mo.md( and extract everything between the opening and closing quotes
    import re
    # Match mo.md with optional whitespace, then capture string with various prefixes
    pattern = r'mo\.md\s*\(\s*[rf]*"""(.*?)"""|mo\.md\s*\(\s*[rf]*\'\'\'(.*?)\'\'\'|mo\.md\s*\(\s*[rf]*"(.*?)"|mo\.md\s*\(\s*[rf]*\'(.*?)\''
    match = re.search(pattern, source, re.DOTALL)
    if match:
        # Return whichever group matched (triple quotes or single quotes)
        for i in range(1, len(match.groups()) + 1):
            if match.group(i) is not None:
                return match.group(i)
    return ''

def build_package(
    notebooks_dir: str = 'notebooks',     # Directory with notebook files
    output_dir: str = 'src',              # Output directory for package
    docstring_style: str = 'nbdev'        # Docstring format
) -> str:                                 # Path to built package
    "Build a Python package from marimo notebook(s)"

    print(f"ðŸ” Scanning notebooks in {notebooks_dir}/")

    # Scan all notebooks
    scan_result = scan_notebooks(notebooks_dir, docstring_style)
    metadata = scan_result['metadata']
    readme_source = scan_result['readme_source']
    modules = scan_result['modules']

    # Get package name from metadata or pyproject.toml
    package_name = metadata.get('__package_name__')
    if not package_name:
        # Try to read from existing pyproject.toml
        try:
            import tomllib
            with open('pyproject.toml', 'rb') as f:
                config = tomllib.load(f)
                package_name = config['project']['name']
        except:
            raise ValueError("No __package_name__ in metadata and no pyproject.toml found")

    package_name = package_name.replace('-', '_')  # Convert to valid Python identifier

    print(f"ðŸ“¦ Building package: {package_name}")

    # Create output directory structure
    package_dir = Path(output_dir) / package_name
    package_dir.mkdir(parents=True, exist_ok=True)

    # Write individual module files
    for module in modules:
        # Skip config files (no exports typically)
        if module['name'].startswith('00_'):
            continue

        if module['exports']:  # Only write if there are exports
            module_file = package_dir / f"{module['name']}.py"
            write_module(
                module['name'],
                module['imports'],
                module['exports'],
                str(module_file)
            )
            print(f"  âœ… {module['name']}.py")

    # Write __init__.py
    init_file = package_dir / '__init__.py'
    write_init(package_name, metadata, modules, str(init_file))

    # Update pyproject.toml with metadata
    if Path('pyproject.toml').exists():
        update_pyproject_toml(metadata, 'pyproject.toml')
    else:
        print("âš ï¸  No pyproject.toml found. Run 'uv init' first.")

    # Extract README if present
    if readme_source:
        extract_readme(readme_source, '.', metadata)

    print(f"\nâœ… Package built in {output_dir}/{package_name}/")
    return str(output_dir)

def add(
    # The first operand
    a:int,
    # This is the second of the operands to the *addition* operator.
    # Note that passing a negative value here is the equivalent of the *subtraction* operator.
    b:int,
)->int: # The result is calculated using Python's builtin `+` operator.
    "Add `a` to `b`"
    return a+b

def convert_docstyle(
    func,                   # The function to convert documentation for
    target_style='google',  # One of 'docments', 'google', or 'numpy'
    include_signature=True  # Whether to include the function signature
) -> str:                   # String representation in the target documentation style
    "Convert function documentation between different styles."

    # Extract all the information we need
    docs_full = docments(func, full=True)
    main_doc = docstring(func)
    func_name = func.__name__
    sig = inspect.signature(func)

    # Separate return from parameters
    params = {k: v for k, v in docs_full.items() if k != 'return'}
    return_info = docs_full.get('return', {})

    if target_style == 'docments':
        return format_docments_style(func_name, params, return_info, main_doc, include_signature)
    elif target_style == 'google':
        return format_google_style(func_name, params, return_info, main_doc, include_signature, sig)
    elif target_style == 'numpy':
        return format_numpy_style(func_name, params, return_info, main_doc, include_signature, sig)
    else:
        raise ValueError(f"Unknown style: {target_style}. Use 'docments', 'google', or 'numpy'")

def format_docments_style(
    func_name,              # Name of the function 
    params: dict,           # Dictionary of parameter information
    return_info: dict,      # Dictionary of return information 
    main_doc: str,          # Main Docustring content
    include_signature:bool, # whether to include the function signature
) -> str:                   # String representation in the target documentation style
    """Format in docments style (inline comments)"""
    lines = [f"def {func_name}("]

    for i, (name, info) in enumerate(params.items()):
        anno = f":{info['anno'].__name__}" if info['anno'] != empty and hasattr(info['anno'], '__name__') else ""
        default = f"={repr(info['default'])}" if info['default'] != empty else ""
        comment = f"  # {info['docment']}" if info['docment'] and info['docment'] != empty else ""
        comma = "," if i < len(params) - 1 else ""
        lines.append(f"    {name}{anno}{default}{comma}{comment}")

    ret_anno = f"->{return_info['anno'].__name__}" if return_info.get('anno') != empty and hasattr(return_info.get('anno'), '__name__') else ""
    ret_comment = f"  # {return_info['docment']}" if return_info.get('docment') and return_info['docment'] != empty else ""
    lines.append(f"){ret_anno}:{ret_comment}")

    if main_doc:
        lines.append(f'    "{main_doc}"')

    return '\n'.join(lines)

def format_google_style(
    func_name,                 # Name of the function
    params,                    # Dictionary of parameter information
    return_info,               # Dictionary of return information
    main_doc,                  # Main docstring content
    include_signature: bool,   # Whether to include the function signature
    sig                        # Function signature object
) -> str:                      # Formatted string in Google style
    "Format in Google style"
    lines = []

    if include_signature:
        lines.append(f"def {func_name}{sig}:")

    # Main docstring
    lines.append('    """' + (main_doc or ""))
    lines.append("")

    # Args section
    if params:
        lines.append("    Args:")
        for name, info in params.items():
            type_str = f" ({info['anno'].__name__})" if info['anno'] != empty and hasattr(info['anno'], '__name__') else ""
            default_str = f", optional, default={repr(info['default'])}" if info['default'] != empty else ""
            desc = info.get('docment', '') or ''
            lines.append(f"        {name}{type_str}: {desc}{default_str}")
        lines.append("")

    # Returns section
    if return_info.get('anno') != empty or return_info.get('docment'):
        lines.append("    Returns:")
        ret_type = return_info.get('anno')
        type_str = f"{ret_type.__name__}: " if ret_type != empty and hasattr(ret_type, '__name__') else ""
        ret_desc = return_info.get('docment', '') or ''
        lines.append(f"        {type_str}{ret_desc}")

    lines.append('    """')
    return '\n'.join(lines)

def format_numpy_style(
    func_name,               # Name of the function
    params,                  # Dictionary of parameter information
    return_info,             # Dictionary of return information
    main_doc,                # Main docstring content
    include_signature:bool,  # Whether to include the function signature
    sig                      # Function signature object
) -> str:                    # Formatted string in NumPy style
    "Format in NumPy style"
    lines = []

    if include_signature:
        lines.append(f"def {func_name}{sig}:")

    # Main docstring
    lines.append('    """' + (main_doc or ""))
    lines.append("")

    # Parameters section
    if params:
        lines.append("    Parameters")
        lines.append("    ----------")
        for name, info in params.items():
            type_str = info['anno'].__name__ if info['anno'] != empty and hasattr(info['anno'], '__name__') else ""
            lines.append(f"    {name} : {type_str}")
            desc = info.get('docment', '') or ''
            if desc:
                # Handle multi-line descriptions
                for desc_line in desc.split('\n'):
                    lines.append(f"        {desc_line}")
            if info['default'] != empty:
                lines.append(f"        (default: {repr(info['default'])})")
        lines.append("")

    # Returns section
    if return_info.get('anno') != empty or return_info.get('docment'):
        lines.append("    Returns")
        lines.append("    -------")
        ret_type = return_info.get('anno')
        type_str = ret_type.__name__ if ret_type != empty and hasattr(ret_type, '__name__') else ""
        lines.append(f"    {type_str}")
        ret_desc = return_info.get('docment', '') or ''
        if ret_desc:
            for desc_line in ret_desc.split('\n'):
                lines.append(f"        {desc_line}")

    lines.append('    """')
    return '\n'.join(lines)

